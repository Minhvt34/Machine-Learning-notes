{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEYlnVOr9qpT4M+yiMp7O7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minhvt34/Machine-Learning-notes/blob/main/Data_Science_Job_skill_and_requirements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Job skill requirement"
      ],
      "metadata": {
        "id": "K39RnH4FGDV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Data Scientist\n",
        "\n",
        "\n",
        "\n",
        "1.   Key Role and Responsibilities \\\\\n",
        "- Identify the data needs of data scientists at our company, document their requirements, and develop robust, secure, and scalable data pipelines to enable and accelerate their analyses.\n",
        "- Own critical data pipelines, help ensure their continued operations, and extend them to meet the needs of the business.\n",
        "- Be on the lookout for potential improvements to our data marts and aggregations that improve their scalability, make them easier for data scientists to use, and reduce potentially dangerous duplication.\n",
        "Help with maintenance and extension of our internal ETL frameworks built on Python and Scala.\n",
        "- Contribute to the development of documentation and educational materials on tools and data pipelines owned by Data Science Foundations. Provide 1-on-1 project support to data scientists and help them get the most of our tools and data.\n",
        "2.   Skill and requirements\n",
        "- You enjoy problem-solving, learning new technologies, and helping others get their work done.\n",
        "- You are excited to work with data-scientists and business stakeholders to deliver real and visible business value. You like to take ownership of your projects and independently build something new and immediately usable.\n",
        "- You have worked as a data engineer handling millions of records per day.\n",
        "- You have experience in SQL and Spark that goes beyond the basics and have worked with Python and/or Scala.\n",
        "- You have experience with using a batch job tool such as Prefect or Airflow (we use Prefect)\n",
        "- You are comfortable working with existing code using git or another VCS in a team-setting.\n",
        "- You must be eligible to work in Japan and be able to conduct business in English to communicate with stakeholders and team members.\n",
        "\n",
        "3. Nice to have \n",
        "\n",
        "- Experience with AWS or cloud computing and cloud infrastructure in general. - Experience with SageMaker, Glue, EMR, S3, RDS, Redshift are a big plus.\n",
        "- You know how to maintain and optimize a PostgreSQL database.\n",
        "- Experience as a data scientist, scientific researcher, or in a data analytics role.\n",
        "- Worked with Terraform or similar Infrastructure as Code technologies.\n",
        "- You are familiar with the concept of CI/CD (CircleCI, Jenkins, ...).\n",
        "- You have worked on a payment platform or other financial technology field.\n",
        "- You have worked with and understand the concept of NoSQL databases and message brokers. Experience with ElasticSearch, Kafka, Cassandra would be useful.\n",
        "\n"
      ],
      "metadata": {
        "id": "Na2Zb8cJGIzo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfVOwR7bGBpi"
      },
      "outputs": [],
      "source": []
    }
  ]
}