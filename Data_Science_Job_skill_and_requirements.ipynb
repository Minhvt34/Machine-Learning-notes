{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwrE8mePvqIUjJaoJ/6Jch",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minhvt34/Machine-Learning-notes/blob/main/Data_Science_Job_skill_and_requirements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Job skill requirement"
      ],
      "metadata": {
        "id": "K39RnH4FGDV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Data Scientist**\n",
        "\n",
        "\n",
        "\n",
        "1.   *Key Role and Responsibilities* \\\\\n",
        "- Identify the data needs of data scientists at our company, document their requirements, and develop robust, secure, and scalable data pipelines to enable and accelerate their analyses.\n",
        "- Own critical data pipelines, help ensure their continued operations, and extend them to meet the needs of the business.\n",
        "- Be on the lookout for potential improvements to our data marts and aggregations that improve their scalability, make them easier for data scientists to use, and reduce potentially dangerous duplication.\n",
        "Help with maintenance and extension of our internal ETL frameworks built on Python and Scala.\n",
        "- Contribute to the development of documentation and educational materials on tools and data pipelines owned by Data Science Foundations. Provide 1-on-1 project support to data scientists and help them get the most of our tools and data.\n",
        "2.   *Skill and requirements*\n",
        "- You enjoy problem-solving, learning new technologies, and helping others get their work done.\n",
        "- You are excited to work with data-scientists and business stakeholders to deliver real and visible business value. You like to take ownership of your projects and independently build something new and immediately usable.\n",
        "- You have worked as a data engineer handling millions of records per day.\n",
        "- You have experience in SQL and Spark that goes beyond the basics and have worked with Python and/or Scala.\n",
        "- You have experience with using a batch job tool such as Prefect or Airflow (we use Prefect)\n",
        "- You are comfortable working with existing code using git or another VCS in a team-setting.\n",
        "- You must be eligible to work in Japan and be able to conduct business in English to communicate with stakeholders and team members.\n",
        "\n",
        "3. *Nice to have* \n",
        "\n",
        "- Experience with AWS or cloud computing and cloud infrastructure in general. - Experience with SageMaker, Glue, EMR, S3, RDS, Redshift are a big plus.\n",
        "- You know how to maintain and optimize a PostgreSQL database.\n",
        "- Experience as a data scientist, scientific researcher, or in a data analytics role.\n",
        "- Worked with Terraform or similar Infrastructure as Code technologies.\n",
        "- You are familiar with the concept of CI/CD (CircleCI, Jenkins, ...).\n",
        "- You have worked on a payment platform or other financial technology field.\n",
        "- You have worked with and understand the concept of NoSQL databases and message brokers. Experience with ElasticSearch, Kafka, Cassandra would be useful.\n",
        "\n"
      ],
      "metadata": {
        "id": "Na2Zb8cJGIzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **Applied Scientist/Engineer**\n",
        "\n",
        "\n",
        "1. *Your daily task*\n",
        "- Apply relevant AI and ML algorithms and techniques to build  intelligent systems that empower large-scale NAVER products.\n",
        "- Train, test, and deploy high-performance ML models for user-facing services continuously.\n",
        "\n",
        "2. *Back ground requirements:*\n",
        "- BS degree in computer science or related field\n",
        "- Experience with deep learning technologies in cv or NLP domain.\n",
        "- Understanding of state-of-the-art deep learning theories, techniques, architectures, and optimization strategies.\n",
        "- Experience with deep learning frameworks such as TensorFlow, Pytorch, Caffe, and MxNet.\n",
        "- Strong programming skills in Linux environment.\n",
        "- Excellent communication skills in English\n",
        "\n",
        "3. *Big plus*\n",
        "- MS or PhD degree in Deep Learning related subjects.\n",
        "- Experience with large-scale distributed systems.\n",
        "- Experience with cost and performance optimization of deep learning models and platforms.*italicized text*\n"
      ],
      "metadata": {
        "id": "6nrTJtenH09m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Data Scientist (Python, Database) - DAT Technologies**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1. *Job Descriptions*\n",
        "\n",
        "As a Data Scientist with NLP and ML skill set, you will be working in a fast-paced environment which needs a mindset of a start-up and an entreprenuer that is not hesitant to constantly shift gears, test and learn.\n",
        "\n",
        "You will be part of the company, you will be working with stakeholders by Agile and Design Thinking Methodologies, innovating and improving the way people invest in share and crypto-currency market with Data Science AI Technology. Together with DAT you will deliver everything from state-of-the-art solutions to quicker value proving solutions.\n",
        "- Data scrapping from FB pages, Zalo, Whatsapp and Telegram's group, and other online materials.\n",
        "- Research, develop and evaluate advanced text processing algorithms and implementations.\n",
        "- Prototype and develop alorithms and advanced machine learning techniques for DAT's features, model and applications.\n",
        "- Stay up to date with tech, prototype with and learn new technologies, proactive in technology communities.\n",
        "- Develop innovatives solutions in areas such as machine learning, computational linguistics, NLP, advanced and semantic information search, extraction, induction, classification and exploration.\n",
        "- Create products that provide a greate user experience along with high performance, security, quality, and stability.\n",
        "- Build and implement advanced ML models for financial/technical data analysis in share market, crypto market.\n",
        "- Collaborate with other teams.\n",
        "\n",
        "2. *Job requirements*\n",
        "- Master's or PhD degree in STEM or AI/ML areas would be a big bonus.\n",
        "- 1+ years of professional experience as a data scientist or related roles.\n",
        "- 1+ years of work experience in text related projects.\n",
        "- 3+ years of work experience in software development, software engineering, software development.\n",
        "- Experience in setting up supervised and unsupervised learning Client/NLP models including data cleaning, data analytics, feature creation, model selection and ensemble methods, performance matrics and visualization.\n",
        "- Knowledge in signal processing techniques including adaptive filtering, filter banks and wavelet processing, speech analysis and synthesis, speech and audio coding.\n",
        "- Experience in text classification topic mining speech enhancement and speech/audio coding and compression.\n",
        "- String experience in prediction using ML and DL.\n",
        "- Hand on experience in feature extraction techniques (GMM, HMM, NMF/ spectrograms, MCFF etc) for voice recognition and audio event classification.\n",
        "\n",
        "- 4+ years of work experience with Python, advance in Pandas, web scrapping.\n",
        "- Hand on experience with ML techniques such as deep neural nets (DNN, CNN, LSTM-RNN).\n",
        "- 3+ years of experience working with Agile team environment.\n",
        "- Experience working in a cloud environment (AWS, Azure, GCP) or a containerized environment (Mesos, Kubernetes).\n",
        "- Good understanding of the complexity of developing and productizing real-world AI/ML applications such as prediction, recommendation, cv, bots, NLP, sentiment, knowledge and content intelligence, etc.\n",
        "- Knowledge of Text Analytics with a strong understanding of Client and NLP algorithms and models (GLMs, SVM, PCA, NB, Clustering, DTs) and their underlying computational and probabilistic statistics.\n",
        "- Deep knowledge of some of the popular ML frameworks such as TensorFlow, scikit-learn.\n",
        "- Designing and documenting data architecture at multiple levels (high-level to detailed) and across multiple levels (conceptual, logical, physical, data flow and sequence diagrams).\n",
        "- Providing active hands-on architectural guidance and leadership through the entire lifecycle of development projects.\n",
        "- Ability to translate business requirements into conceptual and detailed system architecture and technology solutions.\n",
        "- Ability to develop and lead proof-of-concepts, deliver practical, working solutions.\n",
        "- Design, implement and deploy scalable, distributed solutions to support real-time NLP data analytic platform using modern engineering principles and techniques\n",
        "- English - good to communicate and work.\n"
      ],
      "metadata": {
        "id": "ix_t_4KOSYXG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfVOwR7bGBpi"
      },
      "outputs": [],
      "source": []
    }
  ]
}