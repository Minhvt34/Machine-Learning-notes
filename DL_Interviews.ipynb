{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minhvt34/Machine-Learning-notes/blob/main/DL_Interviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EVKHGbFvZpi"
      },
      "source": [
        "SOL-4\n",
        "For a fixed number of observations in a data set, introducing more variables normally generates a model that has a better fit to the data $\\implies$ True, however, when an excessive and unnecessary number of variables is used in a logistic regression model, a phenomena commonly referred to as \"overfitting\". Therefore, it is important that a logistic regression model does not start training with more variables than is justified for the given number of observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXBBNPiCwhwr"
      },
      "source": [
        "SOL-5\n",
        "The odds of sucess are defined as the ratio between the probability of success $p \\in [0, 1]$ and the probability of failure $1 - p$. Formally: \\\\\n",
        "$Odds(p) ≡ \\left(\\frac{p}{1 - p}\\right)$\n",
        "\n",
        "For instace, assuming the probability of success of an event is p = 0.7. Then, in our example, the odds are 7/3, or 2.333 to 1. Natually, in the case of equal probabilities where p = 0.5, the odds of success if 1 to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNycOGmyyXYV"
      },
      "source": [
        "SOL-6\n",
        "1. An interaction is the product of two single predictor variables implying a non-additive effect.\n",
        "2. The simplest interaction model includes a predictor variable formed by multiplying two ordinary predictors. Let us assume two variables X and Z. Then, the logistic regression model that employs the simplest form of interaction follows: \\\\\n",
        "$β_0 + β_1X + β_2Z + β_3XZ$\n",
        "where the coefficient for the interaction term XZ is represented by predictor β_3.\n",
        "\n",
        "3. For testing the contribution of an interaction, two principal methods are commonly employed; the Wald chi-squared test or a likelihood ratio test between the model with and without the interaction term.\n",
        "\n",
        "Note: How does interaction related to information theory? What added value does it employ to enhance model performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f54knUl88llJ"
      },
      "source": [
        "SOL-8\n",
        "In the case of logistic regression, the response variable is the log of the odds of being classified in a group of binary or multi-class reponses.\n",
        "\n",
        "This definition essentially demonstrates that odds can take the form of a vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6DOS5LI-E9b"
      },
      "source": [
        "SOL-9\n",
        "When a transformation to the response variable is applied, it yields a probability distribution over the output classes, which is bounded between 0 and 1; this transformation can be employed i several ways, e.g., a softmax layer, the signmoid function or classic normalization. This representation facilitates a soft-decision by the logistic regression model, which permits construction of probability-based processes over the predictions of the model \n",
        "\n",
        "Note: what are the pros and cons of each of the three aforementioned transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SAjkcNTA_3L"
      },
      "source": [
        "SOL-10\n",
        "\n",
        "Minimizing the negative log likelihood also means maximizing the likelihood of selecting the correct class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frt9n_EwD4_c"
      },
      "source": [
        "SOL-14\n",
        "A binary logistic regression GLM consists of three components:\n",
        "1. Random component: refers to the probability distribution of the response variable (Y), e.g., binomial distributn for Y in the binary logistic regression, which takes on the values Y = 0 or Y = 1.\n",
        "\n",
        "2. Systematic component: describes the explanatory variables:\n",
        "$(X_1, X_2,...)$ as a combination of linear predictors. The binary case does not constrain these variables to any degree.\n",
        "\n",
        "3. Link function: specifies the link between random and systematic components. It says how the expected value of the response relates to the linear predictor of explanatory variables.\n",
        "Note: Assume that Y denotes whether a human voice activity was detected $(Y = 1)$ or not $(Y = 0)$ in a give time frame. Propose two systematic components and a link function adjusted for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lJw5Ym5HAVY"
      },
      "source": [
        "SOL-16\n",
        "\n",
        "The logit function is defined as:\n",
        "$z(p) = logit(p) = log(\\frac{p}{1-p})$ for any $p \\in [0, 1]$. A simple set of algebraic equations yeilds the inverse relation:\n",
        "$p(z) = \\frac{exp z}{1 + exp z}$ which exactly describes the relation between the output and input of the logistic function, aldo known as the signmoid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V08s8CnxJI0q"
      },
      "source": [
        "SOL-19\n",
        "\n",
        "1. Tumour eradication (Y) is the response variable and cancer type (X) is the explanatory variable.\n",
        "\n",
        "2. Relative risk (RR) is the ratio of risk of an event in one group (e.g., exposed group) versus the risk of the event in the other group (e.g., non-exposed group). The odds ratio (OR) is the ratio of odds of an event in one group versus the odds of the event in the other group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzAN69rmW8Ns"
      },
      "source": [
        "def Ver003(x): \\\\\n",
        "  return 1 / (1 + np.exp(-(np.clip(x, -709, None))))\n",
        "\n",
        "  this method is more stability because np.clip() function help to limit the boundary. By specifying the minimm and maximum values in the argument, the out-of-range values are replaced with those values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExdRL5RmXgZ0"
      },
      "source": [
        "PRB-158\n",
        "\\\\\n",
        "Unlike CNN architectures such as AlexNet or VGG, ResNet does not have any hidden FC layer. True, the ResNet architecture terminates with a global average pooling layer followed by a K-way FC layer with a softmax activation, where K is the number of classes (ImageNet has 1000 classes). Therefore, the ResNet has no hidden FC layers."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A successful story about applied Machine Learning\n",
        "\n",
        "How I applied statistics, Machine Learning, Software Engineering, and Domain expertise to successfully deliver a data science project end-to-end at Google.\n",
        "\n",
        "1. Screen for Opportunities\n",
        "\n",
        "It's not always the case that business stakeholders know exactly what they want. Sometimes, there is already a business process they followed for years.\n",
        "\n",
        "For instance, at Google, FP&A analysts in the infrastructure team were using Google sheets and manual calculations to forecast network equipment expenses.\n",
        "\n",
        "My data science team saw that as an opportunity to improve the forecast with machine learning.\n",
        "\n",
        "Your job as a data scientist is to show that there's a better alternative using statistical analysis or models.\n",
        "\n",
        "2. Gather Business Requirements\n",
        "\n",
        "Before you develop the solution, you have to clearly define your project scope and get it signed off.\n",
        "\n",
        "For instance, here were the requirements I gathered in the forecast project.\n",
        "\n",
        "- What are the data sources available?\n",
        "- What is the forecast horizon?\n",
        "- How often do they want the forecast updated? Batch vs Real time.\n",
        "- What is the success benchmark?\n",
        "- e.t.c\n",
        "\n",
        "3. Exploratory Data Analysis\n",
        "EDA is not just about creating pretty plots you see in most data science courses. You conduct EDA to (1) identify the feasibility of the project, (2) craft a story and (3) aid your modeling process.\n",
        "\n",
        "My forecasting solution utilized multivariate signals including window-based signals (e.g. everage cost for the past 12 months).\n",
        "\n",
        "I created correlation matrix, trend, seasonal plots and such for:\n",
        "\n",
        "(1) Feasibility - Is it possible to deliver a solution using the data I have?\n",
        "(2) Story - Can I reveal useful patterns in the data to the stakeholders?\n",
        "(3) Modeling - Do I have the right signal for the model?\n",
        "\n",
        "4. Modeling\n",
        "In general, my process follows:\n",
        "- Data preprocessing & cleaning\n",
        "- Feature engineering (I usually use aggregation-based)\n",
        "- Feature selection (I usually use Lasso)\n",
        "- Model training (I start with XGBoost)\n",
        "- Hyperparameter tuning (I use Bayesian HyperOpt)\n",
        "- Evaluation (MAE, RMSE, and MAPE for forcasting)\n",
        "\n",
        "5. Model serving\n",
        "\n",
        "Now, this is the part where you have to on your coder/ software engineering hat.\n",
        "The model code you built on Jupyter will most likely need a revision. I do the following:\n",
        "\n",
        "- Revise customized preprocessing, feature engineering, etc where I could improve the auxiliary space and runtime complexity (yes, Leetcode style coding problems actually do help me).\n",
        "\n",
        "- Create environments for testing to live version:DEV, UAT, PROD.\n",
        "\n",
        "- Create a modeling orchestration  - we used Plx Workflow (sort of like Airflow)\n",
        "\n",
        "- Set read, write, and execute policy for database, code, and etc.\n",
        "\n",
        "- Write modules of functions for re-use in the next projects.\n",
        "\n",
        "The project doesn't end here just because I \"served\" the model, now there's continual monitoring and stakeholder adoption and check-ins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdz7FNjhvYyM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMyQyoArvCF76DPCB1jVsKU",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
